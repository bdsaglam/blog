{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# How to use a HuggingFace dataset with fastai?\n",
        "- toc: false \n",
        "- badges: true\n",
        "- categories: [fastai, huggingface, datasets]\n",
        "- comments: true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztrwZ2xuvPBb"
      },
      "source": [
        "In this tutorial, we will show you how to use a HuggingFace dataset with fastai to train a model for image classification. We will use the [Beans dataset](https://huggingface.co/datasets/beans), which consists of images of beans with three different types of diseases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCDY0HE4vXWZ"
      },
      "source": [
        "## Step 1: Install the required libraries\n",
        "Before starting, we need to install the required libraries. Run the following commands to install fastai and HuggingFace's datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ygyJd06vV84"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq fastai\n",
        "!pip install -Uqq datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf_C2n3XvwF-"
      },
      "source": [
        "Login to HuggingFace Hub to download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExcWKD_FNwiy"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q7nLyA69vauG"
      },
      "source": [
        "## Step 2: Import the required modules\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IS1iUwavdxN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from fastai.data.all import *\n",
        "from fastai.vision.all import *\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-tJ5cN7vky2"
      },
      "source": [
        "## Step 3: Load the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkSxR9ULwOrl"
      },
      "source": [
        "Let's load [Beans dataset](https://huggingface.co/datasets/beans), which is a dataset of images of beans taken in the field using smartphone cameras. It consists of 3 classes: 2 disease classes and the healthy class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_gzD07eNkZT"
      },
      "outputs": [],
      "source": [
        "raw_ds = load_dataset(\"beans\")\n",
        "raw_ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7f7s0RAwmNa"
      },
      "source": [
        "The dataset is splitted into train, validation, and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWsHxRRXwvlS"
      },
      "source": [
        "Let's see label names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kte9oxiIvosy"
      },
      "outputs": [],
      "source": [
        "class_names = raw_ds['train'].features['labels'].names\n",
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz9_EYr7w6oN"
      },
      "source": [
        "## Step 4: Preprocess the dataset\n",
        "\n",
        "Often, we need preprocessing raw data before training a model with it. HuggingFace `datasets` library provides two methods for preprocessing:\n",
        "\n",
        "1. `map`: This method is used to apply a function to each example in the dataset, possibly in a batched manner. The function can be applied to one or more columns of the dataset, and the result can be stored in a new column or overwrite the existing one. The map function also allows you to remove some columns from the dataset, if needed. This method is useful for preprocessing the dataset, such as resizing images, tokenizing text, or encoding categorical features. It caches outputs so that they're not computed again.\n",
        "\n",
        "2. `set_transforms`: This method is used to set a transform function that is applied on-the-fly when accessing examples from the dataset. This means that the dataset is not modified in-place, and the transform function is applied only when the examples are accessed. This method is useful for applying data augmentation techniques or normalization that should be applied dynamically during training without modifying the dataset beforehand.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzvJMMAk3_Ic"
      },
      "source": [
        "Let's resize each image to 224x244."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMkaTkB8bVzk"
      },
      "outputs": [],
      "source": [
        "def preprocess(records):\n",
        "    records[\"image\"] = [image.convert(\"RGB\").resize((224, 224)) for image in records[\"image\"]]\n",
        "    return records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yznzrJt64I4k"
      },
      "source": [
        "Before batching samples, we need to remove unnecessary columns in the dataset such as `image_file_path`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZxdVDKMbUS4"
      },
      "outputs": [],
      "source": [
        "ds = raw_ds.map(preprocess, remove_columns=[\"image_file_path\"], batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSYR3a0-bw-o"
      },
      "outputs": [],
      "source": [
        "ds['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQRquOEC9dy0"
      },
      "source": [
        "We won't use `set_transform` as fastai's DataBlock can apply item-level and batch-level transforms, e.g. data augmentations. When we use a pretrained model, it actually applies necessary transforms such as normalization automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTcc46Sa5DUz"
      },
      "source": [
        "## Step 5: Create the DataBlock\n",
        "\n",
        "Now, we can create dataloaders for the dataset using DataBlock from fastai. As the dataset is already splitted into train, validation, and test sets, we don't need to split it further. Hence, we will use `nosplit` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILcFj8Ynut0R"
      },
      "outputs": [],
      "source": [
        "def nosplit(items): \n",
        "    return list(range(len(items))), []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2QodbiNptC0"
      },
      "outputs": [],
      "source": [
        "dblock = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_x=lambda record: record['image'],\n",
        "    get_y=lambda record: class_names[record['labels']],\n",
        "    splitter = nosplit,\n",
        ")\n",
        "\n",
        "train_dl = dblock.dataloaders(ds['train']).train\n",
        "valid_dl = dblock.dataloaders(ds['validation']).train\n",
        "dls = DataLoaders(train_dl, valid_dl, device=DEVICE)\n",
        "dls.show_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwitFjUysLQ2"
      },
      "outputs": [],
      "source": [
        "len(dls.train.dataset),len(dls.valid.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gwZzB6X6YbL"
      },
      "source": [
        "## Step 6: Training\n",
        "\n",
        "Let's fine-tune a pretrained ResNet model on our dataset using `Learner.fine_tune` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8ZD4gM16vJ_"
      },
      "outputs": [],
      "source": [
        "# Create a learner\n",
        "learn = vision_learner(\n",
        "    dls, \n",
        "    resnet34, \n",
        "    loss_func=CrossEntropyLossFlat(),\n",
        "    metrics=accuracy, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJnc3nr16xH_"
      },
      "outputs": [],
      "source": [
        "# Find a good learning rate\n",
        "learn.lr_find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXP9F1zF6wqI"
      },
      "outputs": [],
      "source": [
        "# Fine-tune the model\n",
        "learn.fine_tune(3, 1e-3, freeze_epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upz84Hio9E_8"
      },
      "source": [
        "## Step 7: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nihGOZet8VHq"
      },
      "source": [
        "Fine-tuned model achieves 93.97% accuracy on validation set, not too bad!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5xBrkIJ8BWn"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = learn.validate(dl=dls.valid)\n",
        "print(f\"Loss {loss:.6f}\\nAccuracy: {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBDBomef9Ovi"
      },
      "source": [
        "Let's check predictions visually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mk5rrb8Xkjs"
      },
      "outputs": [],
      "source": [
        "learn.show_results(dl=valid_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHcvUA_H8daf"
      },
      "source": [
        "Let's predict and evaluate on test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX0tUrxQwEcj"
      },
      "outputs": [],
      "source": [
        "tst_dl = dls.test_dl(ds['test'], with_labels=True)\n",
        "probs, targets, preds = learn.get_preds(dl=tst_dl, with_decoded=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbrMdK3TYUwr"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = learn.validate(dl=tst_dl)\n",
        "print(f\"Loss {loss:.6f}\\nAccuracy: {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly6QBXRN8oML"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
